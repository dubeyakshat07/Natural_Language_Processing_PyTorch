{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT for sequence classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6df96b7597424365ab26e6b7513bd6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d76329670f545f9a12f7b435b646ba6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_470e1c68b41d44c6a44a044425b09103",
              "IPY_MODEL_2c692eacb48a4ae5b60f96798c84e0f0"
            ]
          }
        },
        "4d76329670f545f9a12f7b435b646ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "470e1c68b41d44c6a44a044425b09103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc71e8bb9f35467d98219c18936f25e7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86cd9583f17542728690bdcbd2e087ba"
          }
        },
        "2c692eacb48a4ae5b60f96798c84e0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4140657df0645ca96a253b4bdc37051",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 752kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_051c82c33fa34c51be39c4468ca189a8"
          }
        },
        "dc71e8bb9f35467d98219c18936f25e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86cd9583f17542728690bdcbd2e087ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4140657df0645ca96a253b4bdc37051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "051c82c33fa34c51be39c4468ca189a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "838451728dd44b948b695b7e321d1fd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce9b18bf08d542f88c9dfb95e24f9bf6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a041c7310de46c3bf0326363a8f42fb",
              "IPY_MODEL_a6a9aebc64734a88921efb374eb08b6b"
            ]
          }
        },
        "ce9b18bf08d542f88c9dfb95e24f9bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a041c7310de46c3bf0326363a8f42fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57a489a7841049ef98140de1b7baa7e7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcaa933e8bdd40d880fb7c463db1242b"
          }
        },
        "a6a9aebc64734a88921efb374eb08b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31863dd2144f4f23a6be9da7fbb22510",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:13&lt;00:00, 31.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fca5e3fa5444f17a780570efef71396"
          }
        },
        "57a489a7841049ef98140de1b7baa7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcaa933e8bdd40d880fb7c463db1242b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31863dd2144f4f23a6be9da7fbb22510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fca5e3fa5444f17a780570efef71396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e6d751151ac472fbb0dda531cd84422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4b357a37555240c0a868704e02ef41c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3011f9ef36754c15b77f9741a033b474",
              "IPY_MODEL_f3f0186589fd442b91ed2b77d3eaf428"
            ]
          }
        },
        "4b357a37555240c0a868704e02ef41c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3011f9ef36754c15b77f9741a033b474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78768cef202246b69bc6ec4e6f48fe43",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cf7d68d952a4d758b0a5af312057b59"
          }
        },
        "f3f0186589fd442b91ed2b77d3eaf428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9283507ff95b4ec79bbddd44e800abe3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 43.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2bab49ad2c144809e1148a1ff6fa71e"
          }
        },
        "78768cef202246b69bc6ec4e6f48fe43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cf7d68d952a4d758b0a5af312057b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9283507ff95b4ec79bbddd44e800abe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2bab49ad2c144809e1148a1ff6fa71e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej",
        "colab_type": "text"
      },
      "source": [
        "#Sentence Classification using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8431a054-3835-4c33-a465-3b63542a903f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Checking for the GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "09e7d809-20ee-40d1-c45b-9c569992aed0"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 33.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 15.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=8aaa7e1fbdf1cfdca5d7cbe9838b8b6b7821a21f29f8fdab7e64fc04e7fa6345\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ZKxKc04Btk",
        "colab_type": "text"
      },
      "source": [
        "We are using [The Corpus of Linguistic Acceptability (CoLA)](https://nyu-mll.github.io/CoLA/) dataset for single sentence classification. It's a set of sentences labeled as grammatically correct or incorrect. It was first published in May of 2018, and is one of the tests included in the \"GLUE Benchmark\" on which models like BERT are competing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "a48c0cf6-700d-42d9-af56-727fa45e9570"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=57410eb6707a58ef29c9e04f4062f3867ea0f14d32cf0065baa0b97f2f9286fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08pO03Ff1BjI",
        "colab_type": "text"
      },
      "source": [
        "The original dataset is available on: https://nyu-mll.github.io/CoLA/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5be0de08-7b87-422d-e783-396f10af4fbf"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./cola_public_1.1.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "4014707a-94ee-40d9-ab32-66af403fe0bb"
      },
      "source": [
        "# Unzipping the dataset\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "e20220fa-7ba5-4f59-d84d-772e95f18eff"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6960</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Minister has arrived.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7967</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>For Aphrodite to appear to be happy would be i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No books survived the fire, did they?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2160</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Terry touched Bill on the shoulder.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2191</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The statue stood on the pedestal.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8410</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I expected there to be a problem.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1628</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>How brave they must believe that you are!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6691</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Emma slighted Miss Bates.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5364</th>\n",
              "      <td>b_73</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Enough is going on to keep them confused.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2307</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Linda taped the label to the cover.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "6960            m_02  ...                          The Minister has arrived.\n",
              "7967            ad03  ...  For Aphrodite to appear to be happy would be i...\n",
              "328             bc01  ...              No books survived the fire, did they?\n",
              "2160            l-93  ...                Terry touched Bill on the shoulder.\n",
              "2191            l-93  ...                  The statue stood on the pedestal.\n",
              "8410            ad03  ...                  I expected there to be a problem.\n",
              "1628            r-67  ...          How brave they must believe that you are!\n",
              "6691            m_02  ...                          Emma slighted Miss Bates.\n",
              "5364            b_73  ...          Enough is going on to keep them confused.\n",
              "2307            l-93  ...                Linda taped the label to the cover.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqIvQaQncdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "61439ea0-6fc6-4556-82d9-11e82b5aa619"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1659</th>\n",
              "      <td>Fluffy is sick, which I slapped a boy who woul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4332</th>\n",
              "      <td>Under the bed wants to be a fun place to hide.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3733</th>\n",
              "      <td>The book, including all the chapters in the fi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6407</th>\n",
              "      <td>Every student in Mary's class, whoever they we...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6568</th>\n",
              "      <td>Where and when did Bill put the book?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "1659  Fluffy is sick, which I slapped a boy who woul...      0\n",
              "4332     Under the bed wants to be a fun place to hide.      0\n",
              "3733  The book, including all the chapters in the fi...      0\n",
              "6407  Every student in Mary's class, whoever they we...      0\n",
              "6568              Where and when did Bill put the book?      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65,
          "referenced_widgets": [
            "6df96b7597424365ab26e6b7513bd6dc",
            "4d76329670f545f9a12f7b435b646ba6",
            "470e1c68b41d44c6a44a044425b09103",
            "2c692eacb48a4ae5b60f96798c84e0f0",
            "dc71e8bb9f35467d98219c18936f25e7",
            "86cd9583f17542728690bdcbd2e087ba",
            "e4140657df0645ca96a253b4bdc37051",
            "051c82c33fa34c51be39c4468ca189a8"
          ]
        },
        "outputId": "5cac4edc-a347-4d50-99d6-9dd1f4fd99d2"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6df96b7597424365ab26e6b7513bd6dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "73326d52-d489-4e06-b706-99e6a5f7d57a"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "043462be-49c9-4a91-92c7-268acf61a6d3"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhUZO9vc_l6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "20d43d20-5b2c-4c51-f3b1-dd59f20646da"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp9BPRd1tMIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will use some utility function from tensorflow(Tensorflow was my first crush)\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "MAX_LEN = 64\n",
        "\n",
        "#Padding the input to the max length that is 64\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDoC24LeEv3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbE-UHvsb7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will call the train_test_split() function from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Performing same steps on the attention masks\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw5K2A5Ko1RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting the input data to the tensor , which can be feeded to the model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#Creating the DataLoader which will help us to load data into the GPU/CPU\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "838451728dd44b948b695b7e321d1fd2",
            "ce9b18bf08d542f88c9dfb95e24f9bf6",
            "2a041c7310de46c3bf0326363a8f42fb",
            "a6a9aebc64734a88921efb374eb08b6b",
            "57a489a7841049ef98140de1b7baa7e7",
            "bcaa933e8bdd40d880fb7c463db1242b",
            "31863dd2144f4f23a6be9da7fbb22510",
            "4fca5e3fa5444f17a780570efef71396",
            "3e6d751151ac472fbb0dda531cd84422",
            "4b357a37555240c0a868704e02ef41c9",
            "3011f9ef36754c15b77f9741a033b474",
            "f3f0186589fd442b91ed2b77d3eaf428",
            "78768cef202246b69bc6ec4e6f48fe43",
            "5cf7d68d952a4d758b0a5af312057b59",
            "9283507ff95b4ec79bbddd44e800abe3",
            "c2bab49ad2c144809e1148a1ff6fa71e"
          ]
        },
        "outputId": "60b3ee08-16e0-464a-f784-684df32628c3"
      },
      "source": [
        "#Loading the pre-trained BERT model from huggingface library\n",
        "\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2,   \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, )\n",
        "\n",
        "# Teeling the model to run on GPU\n",
        "model.cuda()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "838451728dd44b948b695b7e321d1fd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e6d751151ac472fbb0dda531cd84422",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AdamW is an optimizer which is a Adam Optimzier with weight-decay-fix\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8 \n",
        "                )\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3a075bc4-4570-4f37-b8f8-1d31a91d32a9"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "scheduler"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.optim.lr_scheduler.LambdaLR at 0x7f54e5dc0f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the helper function to have a watch on elapsed time\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40adc853-1e64-49ef-a340-7c033918903a"
      },
      "source": [
        "#Let's start the training process\n",
        "\n",
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:54.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:21.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:48.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:42.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:02:43\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:54.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:21.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:48.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:42.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:02:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:54.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:21.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:48.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:41.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:02:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:54.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:21.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:48.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:15.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:42.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:02:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "7c4c0f5f-f977-48d1-8d90-610291d034c7"
      },
      "source": [
        "#Plotting the training loss vs number of epochs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btUsZ5vMyjwt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b3b54514-ed69-448a-a1dd-11480b8af8cd"
      },
      "source": [
        "print(loss_values) #Having a view of stored loss values in the list"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.4956092043041688, 0.3199369729925488, 0.2174745194335696, 0.15056898273311214]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "271cd979-0fd3-4782-8cc1-934802584821"
      },
      "source": [
        "#Loading the test data and applying the same preprocessing techniques which we performed on the train data\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8c65c0d5-4498-44a4-e025-3b29b4e86923"
      },
      "source": [
        "#Evaluating our model on the test set\n",
        "\n",
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv",
        "colab_type": "text"
      },
      "source": [
        "We will use Matthews Correlation Coefficient(MCC) to evaluate our model. \n",
        "MCC is used in many areas of Natural Language Processing. Also, it's a great metric to be used for imbalanced dataset\n",
        "\n",
        "Link: https://towardsdatascience.com/the-best-classification-metric-youve-never-heard-of-the-matthews-correlation-coefficient-3bf50a2f3e9a\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c6b0e7ec-cadb-4300-fca5-60cb8be23cfb"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2f28c93d-1c0f-452b-81b6-2a06f6e05c51"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e0e4026c-b20a-4dab-a817-49874d2b5a73"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAVpj5CArddl",
        "colab_type": "text"
      },
      "source": [
        "We fine-tuned BERT without going into much deeper operations such as hyperparameter tuning. MCC of 0.555 is an okayish score for such tasks and keeping in mind that we didn't trained our model on complete dataset, and very few epochs."
      ]
    }
  ]
}